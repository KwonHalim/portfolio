# AI/lifespan.py

from contextlib import asynccontextmanager

from fastapi import FastAPI

import container.dependency as deps


@asynccontextmanager
async def lifespan(app: FastAPI):
    # --- âš™ï¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰ ---
    print("--- ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘: ì‹±ê¸€í†¤ ê°ì²´ ìƒì„± ---")

    # 1. ë…ë¦½ì ì¸ ë¬´ê±°ìš´ ê°ì²´ë“¤ ë¨¼ì € ìƒì„±
    embedding_strategy = await deps.get_embedding_strategy()
    llm = deps.get_llm()
    chat_db_strategy = deps.get_chat_db_strategy()
    prompt = deps.get_prompt() # ìºì‹±ë˜ë¯€ë¡œ ì—¬ê¸°ì„œ í˜¸ì¶œí•´ë„ ë¬´ë°©

    # 2. ìœ„ì—ì„œ ë§Œë“  ê°ì²´ì— ì˜ì¡´í•˜ëŠ” ê°ì²´ë“¤ ìƒì„±
    vector_store_strategy = await deps.get_vector_store_strategy(embedding_strategy)
    vector_repository = await deps.get_vector_repository(vector_store_strategy)
    chat_repository = deps.get_chat_repository(chat_db_strategy)
    embedding_service = await deps.get_embedding_service(embedding_strategy)
    bm_25_retriever = await deps.get_bm25_retriever(vector_repository)
    retriever = await deps.get_document_retriever(vector_repository, bm_25_retriever)


    # 3. ìºì‹±ëœ ê°€ë²¼ìš´ ê°ì²´ë“¤ë„ ê°€ì ¸ì˜¤ê¸°
    chunk_service = deps.get_chunk_service(deps.get_chunk_strategy())
    data_processor = deps.get_data_processor()

    # 4. ìµœì¢… ì„œë¹„ìŠ¤ ê°ì²´ë“¤ ìƒì„± ë° app.stateì— ì €ì¥
    app.state.rag_service = await deps.get_rag_service(
        chunk_service=chunk_service,
        embedding_service=embedding_service,
        data_processor=data_processor,
        vector_repository=vector_repository,
    )
    app.state.chat_service = await deps.get_chat_service(
        retriever=retriever,
        prompt=prompt,
        llm=llm,
        chat_repository=chat_repository,
        vector_repository=vector_repository,
    )

    print("--- âœ… ì‹±ê¸€í†¤ ê°ì²´ ìƒì„± ì™„ë£Œ ---")
    yield
    # --- ğŸ”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰ ---
    print("--- ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ---")