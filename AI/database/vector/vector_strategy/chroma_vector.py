# strategies/chroma_vector.py
from typing import List, Optional

import chromadb
from langchain_chroma import Chroma
from langchain_core.documents import Document

from database.vector.vector_strategy.vector_store_strategy import VectorStoreStrategy
from service.embedding.embedding_strategy.embedding_strategy import EmbeddingStrategy


class ChromaVector(VectorStoreStrategy):
    def __init__(self, host: str, port: int, embedding_strategy: EmbeddingStrategy):
        """
        ChromaDB ì„œë²„ì— ì—°ê²°í•˜ê³  LangChain Chroma ë˜í¼ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        í”¼ë“œë°± ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ë„¤ì´í‹°ë¸Œ ì»¬ë ‰ì…˜ ê°ì²´ì—ë„ ì ‘ê·¼í•©ë‹ˆë‹¤.
        """
        # LangChain ë˜í¼ê°€ ì‚¬ìš©í•  í´ë¼ì´ì–¸íŠ¸
        self.client = chromadb.HttpClient(host=host, port=port)

        # LangChainì˜ Chroma ë²¡í„°ìŠ¤í† ì–´ ë˜í¼ ì´ˆê¸°í™”
        self.vectorstore = Chroma(
            client=self.client,
            embedding_function=embedding_strategy,
            collection_name= "langchain" #ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©ì˜ˆì •
        )

    def add_documents(self, chunks: List[Document]):
        """
        ë¬¸ì„œë¥¼ ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.
        """
        self.vectorstore.add_documents(documents=chunks)
        print(f"ğŸ’¾ {len(chunks)}ê°œì˜ ë¬¸ì„œë¥¼ ChromaDBì— ì €ì¥ ì™„ë£Œ")

    def query(self, query_text: str, k: int = 3, source_type: Optional[str] = None) -> list[tuple[Document, float]]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  (ë¬¸ì„œ, ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # ê¸°ë³¸ ì¡°ê±´ìœ¼ë¡œ Document.page_contentì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        if source_type:
            results = self.vectorstore.similarity_search_with_relevance_scores(query_text, k=k, source_type=source_type)
        # print(f"ğŸ” '{query_text}' ì¿¼ë¦¬ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
        else:
            results = self.vectorstore.similarity_search_with_relevance_scores(query_text, k=k)
        return results

    def get_all_documents(self) -> List[Document]:
        """
        ChromaDB ì»¬ë ‰ì…˜ì— ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œë¥¼ LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        self.collection = self.client.get_collection(name="langchain")

        count = self.collection.count()
        data = self.collection.get(
            limit=count,
            include=["metadatas", "documents"]
        )

        docs = [
            Document(page_content=doc, metadata=meta)
            for doc, meta in zip(data["documents"], data["metadatas"])
        ]
        return docs