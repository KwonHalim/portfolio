# strategies/chroma_vector.py
from typing import List, Optional

import chromadb
from fastapi.logger import logger
from langchain_chroma import Chroma
from langchain_core.documents import Document

from database.vector.vector_strategy.vector_store_strategy import VectorStoreStrategy
from service.embedding.embedding_strategy.embedding_strategy import EmbeddingStrategy


class ChromaVector(VectorStoreStrategy):
    def __init__(self, host: str, port: int, embedding_strategy: EmbeddingStrategy):
        """
        ChromaDB ì„œë²„ì— ì—°ê²°í•˜ê³  LangChain Chroma ë˜í¼ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        í”¼ë“œë°± ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ë„¤ì´í‹°ë¸Œ ì»¬ë ‰ì…˜ ê°ì²´ì—ë„ ì ‘ê·¼í•©ë‹ˆë‹¤.
        """
        # LangChain ë˜í¼ê°€ ì‚¬ìš©í•  í´ë¼ì´ì–¸íŠ¸
        self.client = chromadb.HttpClient(host=host, port=port)

        # LangChainì˜ Chroma ë²¡í„°ìŠ¤í† ì–´ ë˜í¼ ì´ˆê¸°í™”
        self.vectorstore = Chroma(
            client=self.client,
            embedding_function=embedding_strategy,
            collection_name= "langchain" #ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©ì˜ˆì •
        )

    def add_documents(self, chunks: List[Document]):
        """
        ë¬¸ì„œë¥¼ ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.
        """
        self.vectorstore.add_documents(documents=chunks)
        logger.info(f"ğŸ’¾ {len(chunks)}ê°œì˜ ë¬¸ì„œë¥¼ ChromaDBì— ì €ì¥ ì™„ë£Œ")

    def query(self, query_text: str, k: int = 3, source_type: Optional[str] = None) -> list[tuple[Document, float]]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  (ë¬¸ì„œ, ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # ê¸°ë³¸ ì¡°ê±´ìœ¼ë¡œ Document.page_contentì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        if source_type:
            results = self.vectorstore.similarity_search_with_relevance_scores(query_text, k=k, source_type=source_type)
        # logger.info(f"ğŸ” '{query_text}' ì¿¼ë¦¬ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
        else:
            results = self.vectorstore.similarity_search_with_relevance_scores(query_text, k=k)
        return results

    def get_all_documents(self) -> List[Document]:
        """
        ChromaDB ì»¬ë ‰ì…˜ì— ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œë¥¼ LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        self.collection = self.client.get_collection(name="langchain")

        count = self.collection.count()
        data = self.collection.get(
            limit=count,
            include=["metadatas", "documents"]
        )

        docs = [
            Document(page_content=doc, metadata=meta)
            for doc, meta in zip(data["documents"], data["metadatas"])
        ]
        return docs

    def find_by_source_id(self, source_ids: List[str], is_good: bool):
        # ë„¤ì´í‹°ë¸Œ Chroma ì»¬ë ‰ì…˜ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        collection = self.client.get_collection(name="langchain")
        for source_id in source_ids:
            results = collection.get(
                where={"source_id": source_id},
                limit=1 # _idì˜ ê°’ì€ í•œê°œë§Œ ì¡´ì¬
            )
            if not results or not results['ids']:
                chromadb.logger.info(f"  âŒ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {source_id}")
                continue
            doc_id = results['ids'][0]
            current_metadata = results['metadatas'][0]
            if is_good:
                # ì¢‹ì•„ìš” í•„ë“œ ì¦ê°€
                current_metadata['likes'] = current_metadata.get('likes', 0) + 1
                logger.info(f"  - ID '{doc_id}'ì˜ 'likes'ë¥¼ {current_metadata['likes']}ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")
            elif not is_good:
                # ì‹«ì–´ìš”
                current_metadata['dislikes'] = current_metadata.get('dislikes', 0) + 1
                logger.info(f"  - ID '{doc_id}'ì˜ 'dislikes'ë¥¼ {current_metadata['dislikes']}ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")
            # ì—…ë°ì´íŠ¸ ìˆ˜í–‰
            collection.update(
                ids=[doc_id],
                metadatas=[current_metadata]
            )
            logger.info("âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
