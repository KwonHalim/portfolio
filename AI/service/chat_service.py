# Langchain ë©”ëª¨ë¦¬ ê´€ë ¨ í´ë˜ìŠ¤ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from langchain.memory import ConversationBufferWindowMemory
from langchain_core import memory
from langchain_core.language_models import BaseLanguageModel
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda

# ê¸°ì¡´ì— ì •ì˜í•œ Repositoryì™€ Retrieverë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
from AI.database.chat.repository import ChatRepository
from AI.service.langchain.chat_history import ChatHistory
from AI.service.langchain.document_retriever import DocumentRetriever


class ChatService:
    """
    Langchain ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ê³ ,
    ê²°ê³¼ë¥¼ Repositoryì— ì €ì¥í•˜ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
    """

    def __init__(
        self,
        retriever: DocumentRetriever,
        prompt: ChatPromptTemplate,
        llm: BaseLanguageModel,
        chat_repository: ChatRepository,
    ):
        self.retriever = retriever
        self.prompt = prompt
        self.llm = llm
        self.repository = chat_repository
        print("âœ… ChatService ì´ˆê¸°í™” (Langchain ë©”ëª¨ë¦¬ ì‚¬ìš©)")

    def ask(self, question: str, session_id: str) -> str:
        """
        ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ RAG ì²´ì¸ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ì €ì¥í•œ í›„ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if len(question) > 200:
            return {"answer": "ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 200ì ì´í•˜ë¡œ ì¤„ì—¬ì£¼ì„¸ìš”.", "message_id": None}

        print(f"\n--- ğŸ—£ï¸ ì§ˆë¬¸: {question} (Chat Session: {session_id}) ---")

        retriever_output = self.retriever.invoke(question)
        context = retriever_output["context"]
        source_docs = retriever_output["source_docs"]
        source_ids = [doc.metadata.get("source_id") for doc in source_docs if "source_id" in doc.metadata]
        print(f"--- ğŸ“š ì°¸ê³  ì†ŒìŠ¤ ID: {source_ids} ---")
        chain = self.prompt | self.llm | StrOutputParser()

        answer = chain.invoke({
            "context": context,
            # "chat_history": recent_history,
            "question": question
        })

        metadata = {
            "retrieved_source_ids": source_ids,
            "retrieved_documents": [doc.to_json() for doc in source_docs],
        }

        self.repository.save_chat(answer, question, session_id, metadata)

        # 7. ê²°ê³¼ ë°˜í™˜
        return answer

